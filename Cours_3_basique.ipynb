{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tianarandr/deeplearning-base/blob/main/Cours_3_basique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um8XXR47Josg"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Concatenate, Conv2D, Activation, BatchNormalization, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from tensorflow.keras.optimizers import SGD, Adadelta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTudi7MLJwA5",
        "outputId": "f1a71680-53ba-442f-ef8e-1c4ce578d286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "60000 X Train\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size= 0.5, train_size=0.5, random_state=True)\n",
        "\n",
        "\n",
        "rows, cols, channels = 28, 28, 1\n",
        "\n",
        "\n",
        "#X_train = X_train.reshape(60000, rows*cols)\n",
        "#X_test = X_test.reshape(10000, rows*cols)\n",
        "\n",
        "X_train = X_train.reshape(60000, rows, cols, channels)\n",
        "X_validation = X_validation.reshape(5000, rows, cols, channels)\n",
        "\n",
        "\n",
        "X_test = X_test.reshape(5000, rows, cols, channels)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_validation = X_validation.astype('float32')\n",
        "\n",
        "#Normalisation \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_validation /= 255\n",
        "\n",
        "\n",
        "print(X_train.shape[0],\"X Train\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKS9IV_NJyQV"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_validation = np_utils.to_categorical(y_validation, 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLYhs-ZLJ4Ac",
        "outputId": "bc0b169f-3c69-458a-caa4-2103a093bbda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "200/200 [==============================] - 93s 459ms/step - loss: 0.2903 - accuracy: 0.9155 - val_loss: 0.0735 - val_accuracy: 0.9752\n",
            "Epoch 2/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 0.0437 - val_accuracy: 0.9864\n",
            "Epoch 3/500\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.0357 - val_accuracy: 0.9882\n",
            "Epoch 4/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0359 - val_accuracy: 0.9894\n",
            "Epoch 5/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0349 - val_accuracy: 0.9884\n",
            "Epoch 6/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0353 - val_accuracy: 0.9878\n",
            "Epoch 7/500\n",
            "200/200 [==============================] - 91s 457ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0300 - val_accuracy: 0.9906\n",
            "Epoch 8/500\n",
            "200/200 [==============================] - 91s 455ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0313 - val_accuracy: 0.9888\n",
            "Epoch 9/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0281 - val_accuracy: 0.9928\n",
            "Epoch 10/500\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0300 - val_accuracy: 0.9906\n",
            "Epoch 11/500\n",
            "200/200 [==============================] - 91s 457ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0286 - val_accuracy: 0.9922\n",
            "Epoch 12/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0298 - val_accuracy: 0.9914\n",
            "Epoch 13/500\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
            "Epoch 14/500\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
            "Epoch 15/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0364 - val_accuracy: 0.9910\n",
            "Epoch 16/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0323 - val_accuracy: 0.9904\n",
            "Epoch 17/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0367 - val_accuracy: 0.9916\n",
            "Epoch 18/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.0300 - val_accuracy: 0.9914\n",
            "Epoch 19/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0393 - val_accuracy: 0.9906\n",
            "Epoch 20/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0396 - val_accuracy: 0.9918\n",
            "Epoch 21/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0358 - val_accuracy: 0.9914\n",
            "Epoch 22/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0290 - val_accuracy: 0.9934\n",
            "Epoch 23/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0336 - val_accuracy: 0.9918\n",
            "Epoch 24/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0322 - val_accuracy: 0.9936\n",
            "Epoch 25/500\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0455 - val_accuracy: 0.9920\n",
            "Epoch 26/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0360 - val_accuracy: 0.9932\n",
            "Epoch 27/500\n",
            "200/200 [==============================] - 95s 474ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0394 - val_accuracy: 0.9922\n",
            "Epoch 28/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0391 - val_accuracy: 0.9924\n",
            "Epoch 29/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0348 - val_accuracy: 0.9918\n",
            "Epoch 30/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0488 - val_accuracy: 0.9886\n",
            "Epoch 31/500\n",
            "200/200 [==============================] - 95s 473ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0362 - val_accuracy: 0.9922\n",
            "Epoch 32/500\n",
            "200/200 [==============================] - 95s 473ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0404 - val_accuracy: 0.9918\n",
            "Epoch 33/500\n",
            "200/200 [==============================] - 94s 467ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0370 - val_accuracy: 0.9924\n",
            "Epoch 34/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0367 - val_accuracy: 0.9926\n",
            "Epoch 35/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0391 - val_accuracy: 0.9934\n",
            "Epoch 36/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0440 - val_accuracy: 0.9918\n",
            "Epoch 37/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0398 - val_accuracy: 0.9920\n",
            "Epoch 38/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0399 - val_accuracy: 0.9916\n",
            "Epoch 39/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0416 - val_accuracy: 0.9924\n",
            "Epoch 40/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0611 - val_accuracy: 0.9894\n",
            "Epoch 41/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0428 - val_accuracy: 0.9926\n",
            "Epoch 42/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0469 - val_accuracy: 0.9934\n",
            "Epoch 43/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0444 - val_accuracy: 0.9934\n",
            "Epoch 44/500\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0451 - val_accuracy: 0.9932\n",
            "Epoch 45/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0508 - val_accuracy: 0.9918\n",
            "Epoch 46/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0498 - val_accuracy: 0.9908\n",
            "Epoch 47/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 9.9024e-04 - accuracy: 0.9997 - val_loss: 0.0382 - val_accuracy: 0.9938\n",
            "Epoch 48/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0414 - val_accuracy: 0.9918\n",
            "Epoch 49/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0463 - val_accuracy: 0.9912\n",
            "Epoch 50/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0454 - val_accuracy: 0.9920\n",
            "Epoch 51/500\n",
            "200/200 [==============================] - 92s 458ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0448 - val_accuracy: 0.9920\n",
            "Epoch 52/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0492 - val_accuracy: 0.9926\n",
            "Epoch 53/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0527 - val_accuracy: 0.9912\n",
            "Epoch 54/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0440 - val_accuracy: 0.9922\n",
            "Epoch 55/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0467 - val_accuracy: 0.9924\n",
            "Epoch 56/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0480 - val_accuracy: 0.9922\n",
            "Epoch 57/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0446 - val_accuracy: 0.9926\n",
            "Epoch 58/500\n",
            "200/200 [==============================] - 94s 472ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0544 - val_accuracy: 0.9922\n",
            "Epoch 59/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0493 - val_accuracy: 0.9926\n",
            "Epoch 60/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0455 - val_accuracy: 0.9930\n",
            "Epoch 61/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0415 - val_accuracy: 0.9924\n",
            "Epoch 62/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0512 - val_accuracy: 0.9914\n",
            "Epoch 63/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0434 - val_accuracy: 0.9938\n",
            "Epoch 64/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 6.1470e-04 - accuracy: 0.9998 - val_loss: 0.0500 - val_accuracy: 0.9934\n",
            "Epoch 65/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0549 - val_accuracy: 0.9910\n",
            "Epoch 66/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0489 - val_accuracy: 0.9924\n",
            "Epoch 67/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
            "Epoch 68/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0494 - val_accuracy: 0.9910\n",
            "Epoch 69/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0592 - val_accuracy: 0.9898\n",
            "Epoch 70/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0503 - val_accuracy: 0.9914\n",
            "Epoch 71/500\n",
            "200/200 [==============================] - 95s 474ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0484 - val_accuracy: 0.9924\n",
            "Epoch 72/500\n",
            "200/200 [==============================] - 96s 478ms/step - loss: 7.0103e-04 - accuracy: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9904\n",
            "Epoch 73/500\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0551 - val_accuracy: 0.9914\n",
            "Epoch 74/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0550 - val_accuracy: 0.9906\n",
            "Epoch 75/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0477 - val_accuracy: 0.9916\n",
            "Epoch 76/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0475 - val_accuracy: 0.9924\n",
            "Epoch 77/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
            "Epoch 78/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0403 - val_accuracy: 0.9920\n",
            "Epoch 79/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 9.9971e-04 - accuracy: 0.9997 - val_loss: 0.0440 - val_accuracy: 0.9920\n",
            "Epoch 80/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0513 - val_accuracy: 0.9926\n",
            "Epoch 81/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.3811e-04 - accuracy: 0.9999 - val_loss: 0.0468 - val_accuracy: 0.9922\n",
            "Epoch 82/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 6.5227e-04 - accuracy: 0.9999 - val_loss: 0.0617 - val_accuracy: 0.9916\n",
            "Epoch 83/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0565 - val_accuracy: 0.9908\n",
            "Epoch 84/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0489 - val_accuracy: 0.9912\n",
            "Epoch 85/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0500 - val_accuracy: 0.9916\n",
            "Epoch 86/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0558 - val_accuracy: 0.9918\n",
            "Epoch 87/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 3.6961e-04 - accuracy: 0.9999 - val_loss: 0.0563 - val_accuracy: 0.9928\n",
            "Epoch 88/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0538 - val_accuracy: 0.9914\n",
            "Epoch 89/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 7.3833e-04 - accuracy: 0.9998 - val_loss: 0.0610 - val_accuracy: 0.9920\n",
            "Epoch 90/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0537 - val_accuracy: 0.9918\n",
            "Epoch 91/500\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0583 - val_accuracy: 0.9926\n",
            "Epoch 92/500\n",
            "200/200 [==============================] - 92s 458ms/step - loss: 8.5525e-04 - accuracy: 0.9997 - val_loss: 0.0545 - val_accuracy: 0.9924\n",
            "Epoch 93/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 6.6078e-04 - accuracy: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9932\n",
            "Epoch 94/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 7.0893e-04 - accuracy: 0.9999 - val_loss: 0.0490 - val_accuracy: 0.9926\n",
            "Epoch 95/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 2.8643e-04 - accuracy: 0.9999 - val_loss: 0.0572 - val_accuracy: 0.9922\n",
            "Epoch 96/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 8.0821e-04 - accuracy: 0.9998 - val_loss: 0.0547 - val_accuracy: 0.9928\n",
            "Epoch 97/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0540 - val_accuracy: 0.9918\n",
            "Epoch 98/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0645 - val_accuracy: 0.9912\n",
            "Epoch 99/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0557 - val_accuracy: 0.9920\n",
            "Epoch 100/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 9.7659e-04 - accuracy: 0.9996 - val_loss: 0.0514 - val_accuracy: 0.9918\n",
            "Epoch 101/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 9.5224e-04 - accuracy: 0.9997 - val_loss: 0.0601 - val_accuracy: 0.9920\n",
            "Epoch 102/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0503 - val_accuracy: 0.9902\n",
            "Epoch 103/500\n",
            "200/200 [==============================] - 95s 475ms/step - loss: 7.7557e-04 - accuracy: 0.9997 - val_loss: 0.0478 - val_accuracy: 0.9922\n",
            "Epoch 104/500\n",
            "200/200 [==============================] - 95s 473ms/step - loss: 7.3479e-04 - accuracy: 0.9998 - val_loss: 0.0612 - val_accuracy: 0.9914\n",
            "Epoch 105/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 8.0368e-04 - accuracy: 0.9998 - val_loss: 0.0545 - val_accuracy: 0.9920\n",
            "Epoch 106/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 7.2669e-04 - accuracy: 0.9998 - val_loss: 0.0555 - val_accuracy: 0.9930\n",
            "Epoch 107/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 5.0210e-04 - accuracy: 0.9998 - val_loss: 0.0538 - val_accuracy: 0.9920\n",
            "Epoch 108/500\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0641 - val_accuracy: 0.9916\n",
            "Epoch 109/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0654 - val_accuracy: 0.9904\n",
            "Epoch 110/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0524 - val_accuracy: 0.9936\n",
            "Epoch 111/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 9.2041e-04 - accuracy: 0.9996 - val_loss: 0.0573 - val_accuracy: 0.9928\n",
            "Epoch 112/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 4.4668e-04 - accuracy: 0.9998 - val_loss: 0.0589 - val_accuracy: 0.9924\n",
            "Epoch 113/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 3.5705e-04 - accuracy: 0.9999 - val_loss: 0.0527 - val_accuracy: 0.9922\n",
            "Epoch 114/500\n",
            "200/200 [==============================] - 92s 459ms/step - loss: 4.9424e-04 - accuracy: 0.9998 - val_loss: 0.0625 - val_accuracy: 0.9930\n",
            "Epoch 115/500\n",
            "200/200 [==============================] - 92s 460ms/step - loss: 5.3771e-04 - accuracy: 0.9998 - val_loss: 0.0714 - val_accuracy: 0.9924\n",
            "Epoch 116/500\n",
            "200/200 [==============================] - 94s 472ms/step - loss: 4.5952e-04 - accuracy: 0.9998 - val_loss: 0.0658 - val_accuracy: 0.9918\n",
            "Epoch 117/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 5.5436e-04 - accuracy: 0.9999 - val_loss: 0.0580 - val_accuracy: 0.9930\n",
            "Epoch 118/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 6.0630e-04 - accuracy: 0.9998 - val_loss: 0.0621 - val_accuracy: 0.9922\n",
            "Epoch 119/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0642 - val_accuracy: 0.9920\n",
            "Epoch 120/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0599 - val_accuracy: 0.9924\n",
            "Epoch 121/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 6.6209e-04 - accuracy: 0.9998 - val_loss: 0.0729 - val_accuracy: 0.9906\n",
            "Epoch 122/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 3.1170e-04 - accuracy: 0.9999 - val_loss: 0.0629 - val_accuracy: 0.9926\n",
            "Epoch 123/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 2.1438e-04 - accuracy: 0.9999 - val_loss: 0.0649 - val_accuracy: 0.9920\n",
            "Epoch 124/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0607 - val_accuracy: 0.9926\n",
            "Epoch 125/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0714 - val_accuracy: 0.9916\n",
            "Epoch 126/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.6854e-04 - accuracy: 0.9998 - val_loss: 0.0611 - val_accuracy: 0.9918\n",
            "Epoch 127/500\n",
            "200/200 [==============================] - 91s 456ms/step - loss: 6.6377e-04 - accuracy: 0.9998 - val_loss: 0.0604 - val_accuracy: 0.9920\n",
            "Epoch 128/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 7.0852e-04 - accuracy: 0.9998 - val_loss: 0.0683 - val_accuracy: 0.9928\n",
            "Epoch 129/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 5.1091e-04 - accuracy: 0.9998 - val_loss: 0.0674 - val_accuracy: 0.9924\n",
            "Epoch 130/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0672 - val_accuracy: 0.9930\n",
            "Epoch 131/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0620 - val_accuracy: 0.9932\n",
            "Epoch 132/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 6.2381e-04 - accuracy: 0.9998 - val_loss: 0.0683 - val_accuracy: 0.9932\n",
            "Epoch 133/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0752 - val_accuracy: 0.9930\n",
            "Epoch 134/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 5.2370e-04 - accuracy: 0.9998 - val_loss: 0.0724 - val_accuracy: 0.9920\n",
            "Epoch 135/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 6.0437e-04 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9908\n",
            "Epoch 136/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.1616e-04 - accuracy: 0.9998 - val_loss: 0.0595 - val_accuracy: 0.9914\n",
            "Epoch 137/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0749 - val_accuracy: 0.9912\n",
            "Epoch 138/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 6.0355e-04 - accuracy: 0.9998 - val_loss: 0.0595 - val_accuracy: 0.9924\n",
            "Epoch 139/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 3.1210e-04 - accuracy: 0.9999 - val_loss: 0.0579 - val_accuracy: 0.9932\n",
            "Epoch 140/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 6.7492e-04 - accuracy: 0.9997 - val_loss: 0.0698 - val_accuracy: 0.9922\n",
            "Epoch 141/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0760 - val_accuracy: 0.9918\n",
            "Epoch 142/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0595 - val_accuracy: 0.9916\n",
            "Epoch 143/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 5.4591e-04 - accuracy: 0.9998 - val_loss: 0.0682 - val_accuracy: 0.9918\n",
            "Epoch 144/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 5.9417e-04 - accuracy: 0.9998 - val_loss: 0.0614 - val_accuracy: 0.9924\n",
            "Epoch 145/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 7.6309e-04 - accuracy: 0.9997 - val_loss: 0.0705 - val_accuracy: 0.9926\n",
            "Epoch 146/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0665 - val_accuracy: 0.9920\n",
            "Epoch 147/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 9.1326e-04 - accuracy: 0.9997 - val_loss: 0.0623 - val_accuracy: 0.9916\n",
            "Epoch 148/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.0946e-04 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9930\n",
            "Epoch 149/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 4.7567e-04 - accuracy: 0.9998 - val_loss: 0.0673 - val_accuracy: 0.9926\n",
            "Epoch 150/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 5.9802e-04 - accuracy: 0.9998 - val_loss: 0.0608 - val_accuracy: 0.9926\n",
            "Epoch 151/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 9.6207e-04 - accuracy: 0.9997 - val_loss: 0.0577 - val_accuracy: 0.9920\n",
            "Epoch 152/500\n",
            "200/200 [==============================] - 92s 461ms/step - loss: 5.3998e-04 - accuracy: 0.9998 - val_loss: 0.0568 - val_accuracy: 0.9932\n",
            "Epoch 153/500\n",
            "200/200 [==============================] - 92s 458ms/step - loss: 5.0260e-04 - accuracy: 0.9999 - val_loss: 0.0635 - val_accuracy: 0.9918\n",
            "Epoch 154/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 1.9194e-04 - accuracy: 0.9999 - val_loss: 0.0560 - val_accuracy: 0.9932\n",
            "Epoch 155/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 4.6140e-04 - accuracy: 0.9998 - val_loss: 0.0573 - val_accuracy: 0.9936\n",
            "Epoch 156/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 5.1339e-04 - accuracy: 0.9998 - val_loss: 0.0580 - val_accuracy: 0.9930\n",
            "Epoch 157/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 9.1112e-04 - accuracy: 0.9997 - val_loss: 0.0665 - val_accuracy: 0.9918\n",
            "Epoch 158/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0637 - val_accuracy: 0.9918\n",
            "Epoch 159/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0757 - val_accuracy: 0.9916\n",
            "Epoch 160/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 7.2785e-04 - accuracy: 0.9998 - val_loss: 0.0636 - val_accuracy: 0.9930\n",
            "Epoch 161/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 5.4035e-04 - accuracy: 0.9999 - val_loss: 0.0722 - val_accuracy: 0.9922\n",
            "Epoch 162/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 2.7845e-04 - accuracy: 0.9999 - val_loss: 0.0600 - val_accuracy: 0.9938\n",
            "Epoch 163/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 8.6915e-04 - accuracy: 0.9997 - val_loss: 0.0732 - val_accuracy: 0.9914\n",
            "Epoch 164/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 6.7779e-04 - accuracy: 0.9998 - val_loss: 0.0772 - val_accuracy: 0.9916\n",
            "Epoch 165/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 6.6231e-04 - accuracy: 0.9998 - val_loss: 0.0641 - val_accuracy: 0.9928\n",
            "Epoch 166/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.3482e-04 - accuracy: 0.9998 - val_loss: 0.0616 - val_accuracy: 0.9916\n",
            "Epoch 167/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 8.3749e-04 - accuracy: 0.9997 - val_loss: 0.0739 - val_accuracy: 0.9918\n",
            "Epoch 168/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 6.6852e-04 - accuracy: 0.9997 - val_loss: 0.0774 - val_accuracy: 0.9918\n",
            "Epoch 169/500\n",
            "200/200 [==============================] - 94s 471ms/step - loss: 6.8117e-04 - accuracy: 0.9997 - val_loss: 0.0762 - val_accuracy: 0.9908\n",
            "Epoch 170/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 8.6996e-04 - accuracy: 0.9997 - val_loss: 0.0816 - val_accuracy: 0.9912\n",
            "Epoch 171/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 9.4426e-04 - accuracy: 0.9997 - val_loss: 0.0665 - val_accuracy: 0.9922\n",
            "Epoch 172/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0574 - val_accuracy: 0.9918\n",
            "Epoch 173/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9922\n",
            "Epoch 174/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 4.5741e-04 - accuracy: 0.9998 - val_loss: 0.0589 - val_accuracy: 0.9930\n",
            "Epoch 175/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 2.3190e-04 - accuracy: 0.9999 - val_loss: 0.0600 - val_accuracy: 0.9922\n",
            "Epoch 176/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 1.4197e-04 - accuracy: 0.9999 - val_loss: 0.0621 - val_accuracy: 0.9928\n",
            "Epoch 177/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 5.8857e-04 - accuracy: 0.9999 - val_loss: 0.0524 - val_accuracy: 0.9932\n",
            "Epoch 178/500\n",
            "200/200 [==============================] - 92s 462ms/step - loss: 5.3111e-04 - accuracy: 0.9998 - val_loss: 0.0583 - val_accuracy: 0.9934\n",
            "Epoch 179/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0703 - val_accuracy: 0.9920\n",
            "Epoch 180/500\n",
            "200/200 [==============================] - 94s 468ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0769 - val_accuracy: 0.9914\n",
            "Epoch 181/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0711 - val_accuracy: 0.9926\n",
            "Epoch 182/500\n",
            "200/200 [==============================] - 96s 480ms/step - loss: 4.7476e-04 - accuracy: 0.9999 - val_loss: 0.0539 - val_accuracy: 0.9930\n",
            "Epoch 183/500\n",
            "200/200 [==============================] - 98s 488ms/step - loss: 2.1509e-04 - accuracy: 0.9999 - val_loss: 0.0606 - val_accuracy: 0.9930\n",
            "Epoch 184/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 5.7805e-04 - accuracy: 0.9998 - val_loss: 0.0812 - val_accuracy: 0.9926\n",
            "Epoch 185/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 6.7445e-04 - accuracy: 0.9998 - val_loss: 0.0565 - val_accuracy: 0.9932\n",
            "Epoch 186/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0637 - val_accuracy: 0.9916\n",
            "Epoch 187/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0635 - val_accuracy: 0.9928\n",
            "Epoch 188/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 1.7224e-04 - accuracy: 0.9999 - val_loss: 0.0714 - val_accuracy: 0.9922\n",
            "Epoch 189/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.4574e-04 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9926\n",
            "Epoch 190/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 5.4392e-04 - accuracy: 0.9999 - val_loss: 0.0609 - val_accuracy: 0.9924\n",
            "Epoch 191/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 5.7433e-05 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9938\n",
            "Epoch 192/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 1.5791e-04 - accuracy: 0.9999 - val_loss: 0.0587 - val_accuracy: 0.9926\n",
            "Epoch 193/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 9.9930e-04 - accuracy: 0.9998 - val_loss: 0.0569 - val_accuracy: 0.9936\n",
            "Epoch 194/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 8.3536e-04 - accuracy: 0.9997 - val_loss: 0.0679 - val_accuracy: 0.9928\n",
            "Epoch 195/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9920\n",
            "Epoch 196/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 7.6906e-04 - accuracy: 0.9998 - val_loss: 0.0695 - val_accuracy: 0.9924\n",
            "Epoch 197/500\n",
            "200/200 [==============================] - 94s 470ms/step - loss: 3.2965e-04 - accuracy: 0.9999 - val_loss: 0.0556 - val_accuracy: 0.9936\n",
            "Epoch 198/500\n",
            "200/200 [==============================] - 93s 465ms/step - loss: 5.5524e-04 - accuracy: 0.9999 - val_loss: 0.0623 - val_accuracy: 0.9934\n",
            "Epoch 199/500\n",
            "200/200 [==============================] - 94s 469ms/step - loss: 2.5423e-04 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9934\n",
            "Epoch 200/500\n",
            "200/200 [==============================] - 93s 467ms/step - loss: 5.7674e-04 - accuracy: 0.9998 - val_loss: 0.0683 - val_accuracy: 0.9928\n",
            "Epoch 201/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0730 - val_accuracy: 0.9922\n",
            "Epoch 202/500\n",
            "200/200 [==============================] - 93s 466ms/step - loss: 4.6157e-04 - accuracy: 0.9999 - val_loss: 0.0639 - val_accuracy: 0.9934\n",
            "Epoch 203/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 3.1345e-04 - accuracy: 0.9999 - val_loss: 0.0724 - val_accuracy: 0.9920\n",
            "Epoch 204/500\n",
            "200/200 [==============================] - 93s 463ms/step - loss: 3.4910e-04 - accuracy: 0.9999 - val_loss: 0.0837 - val_accuracy: 0.9920\n",
            "Epoch 205/500\n",
            "200/200 [==============================] - 93s 464ms/step - loss: 4.0286e-04 - accuracy: 0.9999 - val_loss: 0.0761 - val_accuracy: 0.9922\n",
            "Epoch 206/500\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 1.1808e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9928\n",
            "Epoch 207/500\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 4.0125e-04 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9926\n",
            "Epoch 208/500\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 3.7913e-04 - accuracy: 0.9999 - val_loss: 0.0730 - val_accuracy: 0.9920\n",
            "Epoch 209/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0765 - val_accuracy: 0.9912\n",
            "Epoch 210/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0741 - val_accuracy: 0.9918\n",
            "Epoch 211/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 9.5702e-04 - accuracy: 0.9997 - val_loss: 0.0633 - val_accuracy: 0.9922\n",
            "Epoch 212/500\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 3.8667e-04 - accuracy: 0.9998 - val_loss: 0.0707 - val_accuracy: 0.9928\n",
            "Epoch 213/500\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 7.2030e-04 - accuracy: 0.9998 - val_loss: 0.0642 - val_accuracy: 0.9926\n",
            "Epoch 214/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 7.4578e-04 - accuracy: 0.9998 - val_loss: 0.0865 - val_accuracy: 0.9916\n",
            "Epoch 215/500\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 9.0491e-04 - accuracy: 0.9998 - val_loss: 0.0670 - val_accuracy: 0.9924\n",
            "Epoch 216/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 7.6659e-04 - accuracy: 0.9999 - val_loss: 0.0893 - val_accuracy: 0.9914\n",
            "Epoch 217/500\n",
            "200/200 [==============================] - 89s 444ms/step - loss: 6.0631e-04 - accuracy: 0.9998 - val_loss: 0.0820 - val_accuracy: 0.9912\n",
            "Epoch 218/500\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 3.2073e-04 - accuracy: 0.9998 - val_loss: 0.0742 - val_accuracy: 0.9922\n",
            "Epoch 219/500\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 2.1840e-04 - accuracy: 0.9999 - val_loss: 0.0717 - val_accuracy: 0.9926\n",
            "Epoch 220/500\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9928\n",
            "Epoch 221/500\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 3.3203e-04 - accuracy: 0.9999 - val_loss: 0.0701 - val_accuracy: 0.9924\n",
            "Epoch 222/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 7.7685e-04 - accuracy: 0.9998 - val_loss: 0.0492 - val_accuracy: 0.9932\n",
            "Epoch 223/500\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 7.1564e-04 - accuracy: 0.9998 - val_loss: 0.0821 - val_accuracy: 0.9924\n",
            "Epoch 224/500\n",
            "200/200 [==============================] - 90s 451ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0712 - val_accuracy: 0.9924\n",
            "Epoch 225/500\n",
            "200/200 [==============================] - 90s 450ms/step - loss: 5.1735e-04 - accuracy: 0.9998 - val_loss: 0.0634 - val_accuracy: 0.9938\n",
            "Epoch 226/500\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 2.6366e-04 - accuracy: 0.9999 - val_loss: 0.0697 - val_accuracy: 0.9930\n",
            "Epoch 227/500\n",
            "200/200 [==============================] - 91s 454ms/step - loss: 4.5390e-04 - accuracy: 0.9999 - val_loss: 0.0639 - val_accuracy: 0.9926\n",
            "Epoch 228/500\n",
            "200/200 [==============================] - 90s 452ms/step - loss: 2.0779e-04 - accuracy: 0.9999 - val_loss: 0.0597 - val_accuracy: 0.9934\n",
            "Epoch 229/500\n",
            "200/200 [==============================] - 91s 453ms/step - loss: 2.7084e-04 - accuracy: 0.9999 - val_loss: 0.0693 - val_accuracy: 0.9936\n",
            "Epoch 230/500\n",
            "200/200 [==============================] - 90s 449ms/step - loss: 1.7300e-05 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9934\n",
            "Epoch 231/500\n",
            "200/200 [==============================] - 90s 448ms/step - loss: 2.4701e-04 - accuracy: 0.9999 - val_loss: 0.0571 - val_accuracy: 0.9934\n",
            "Epoch 232/500\n",
            "200/200 [==============================] - 89s 447ms/step - loss: 5.4549e-04 - accuracy: 0.9998 - val_loss: 0.0742 - val_accuracy: 0.9920\n",
            "Epoch 233/500\n",
            "200/200 [==============================] - 89s 447ms/step - loss: 6.7322e-04 - accuracy: 0.9998 - val_loss: 0.0723 - val_accuracy: 0.9930\n",
            "Epoch 234/500\n",
            " 28/200 [===>..........................] - ETA: 1:15 - loss: 2.5431e-04 - accuracy: 0.9999"
          ]
        }
      ],
      "source": [
        "#Model d'architecture\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "learning_rate =0.5\n",
        "batch_size = 300\n",
        "np_epochs = 500\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28,1)))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer=tf.keras.optimizers.Adam(),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=np_epochs, batch_size=batch_size, validation_data=(X_validation, y_validation))\n",
        "\n",
        "#seaborn"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Cours 3 basique.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwg2KBpTMlxXX696msW2NT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}